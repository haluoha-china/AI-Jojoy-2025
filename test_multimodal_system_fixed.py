#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡æ€å‘é‡åŒ–ç³»ç»ŸåŠŸèƒ½æµ‹è¯• (ä¿®å¤ç‰ˆæœ¬)
è§£å†³PILå’ŒFAISSå…¼å®¹æ€§é—®é¢˜
"""

import os
import sys
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import librosa
import soundfile as sf
import easyocr
from transformers import pipeline
from sentence_transformers import SentenceTransformer
import faiss
import torch

def test_environment():
    """æµ‹è¯•ç¯å¢ƒä¾èµ–"""
    print("ğŸ” æµ‹è¯•ç¯å¢ƒä¾èµ–...")
    
    try:
        # PyTorchå’ŒCUDA
        print(f"âœ… PyTorch: {torch.__version__}")
        print(f"âœ… CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"âœ… GPUè®¾å¤‡: {torch.cuda.get_device_name()}")
        
        # OpenCV
        print(f"âœ… OpenCV: {cv2.__version__}")
        
        # NumPy
        print(f"âœ… NumPy: {np.__version__}")
        
        # PIL/Pillow
        try:
            from PIL import Image
            print("âœ… PIL/Pillow: å¯ç”¨")
        except ImportError:
            print("âŒ PIL/Pillow: ä¸å¯ç”¨")
        
        # Matplotlib
        print(f"âœ… Matplotlib: {plt.matplotlib.__version__}")
        
        # Seaborn
        print(f"âœ… Seaborn: {sns.__version__}")
        
        # Plotly
        print(f"âœ… Plotly: {plotly.__version__}")
        
        # Librosa
        print(f"âœ… Librosa: {librosa.__version__}")
        
        # SentenceTransformers
        try:
            from sentence_transformers import SentenceTransformer
            print("âœ… SentenceTransformers: å¯ç”¨")
        except ImportError:
            print("âŒ SentenceTransformers: ä¸å¯ç”¨")
        
        # LangChain FAISS
        try:
            import faiss
            print("âœ… LangChain FAISS: å¯ç”¨")
        except ImportError:
            print("âŒ LangChain FAISS: ä¸å¯ç”¨")
        
        # EasyOCR
        try:
            import easyocr
            print("âœ… EasyOCR: å¯ç”¨")
        except ImportError:
            print("âŒ EasyOCR: ä¸å¯ç”¨")
        
        # Transformers Pipeline
        try:
            from transformers import pipeline
            print("âœ… Transformers Pipeline: å¯ç”¨")
        except ImportError:
            print("âŒ Transformers Pipeline: ä¸å¯ç”¨")
        
        print("\nğŸ‰ æ‰€æœ‰ç¯å¢ƒä¾èµ–æ£€æŸ¥é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ ç¯å¢ƒä¾èµ–æ£€æŸ¥å¤±è´¥: {e}")
        return False

def test_ocr_functionality():
    """æµ‹è¯•OCRåŠŸèƒ½ (ä¿®å¤PILå…¼å®¹æ€§é—®é¢˜)"""
    print("\nğŸ” æµ‹è¯•OCRåŠŸèƒ½...")
    
    try:
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image_path = "test_ocr_image.png"
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾åƒ
        img = np.ones((100, 300, 3), dtype=np.uint8) * 255
        cv2.putText(img, "Hello World", (50, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)
        cv2.imwrite(test_image_path, img)
        
        # åˆå§‹åŒ–EasyOCR
        reader = easyocr.Reader(['en'], gpu=False)  # ä½¿ç”¨CPUé¿å…GPUé—®é¢˜
        
        # æ‰§è¡ŒOCR
        results = reader.readtext(test_image_path)
        
        if results:
            print(f"âœ… OCRè¯†åˆ«æˆåŠŸ: {len(results)} ä¸ªæ–‡æœ¬åŒºåŸŸ")
            for i, (bbox, text, confidence) in enumerate(results):
                print(f"  æ–‡æœ¬{i+1}: '{text}' (ç½®ä¿¡åº¦: {confidence:.3f})")
        else:
            print("âš ï¸ OCRæœªè¯†åˆ«åˆ°æ–‡æœ¬")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(test_image_path):
            os.remove(test_image_path)
        
        return True
        
    except Exception as e:
        print(f"âŒ OCRæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_image_processing():
    """æµ‹è¯•å›¾åƒå¤„ç†åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•å›¾åƒå¤„ç†åŠŸèƒ½...")
    
    try:
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        test_image_path = "test_image.png"
        
        # åˆ›å»ºä¸€ä¸ªå½©è‰²æµ‹è¯•å›¾åƒ
        img = np.random.randint(0, 255, (300, 400, 3), dtype=np.uint8)
        cv2.imwrite(test_image_path, img)
        
        # è¯»å–å›¾åƒ
        image = cv2.imread(test_image_path)
        height, width, channels = image.shape
        
        # è®¡ç®—åŸºæœ¬ç‰¹å¾
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        brightness = np.mean(gray)
        contrast = np.std(gray)
        
        print(f"âœ… å›¾åƒä¿¡æ¯: {width}x{height}, é€šé“æ•°: {channels}")
        print(f"âœ… äº®åº¦: {brightness:.1f}, å¯¹æ¯”åº¦: {contrast:.1f}")
        
        # æµ‹è¯•PILå…¼å®¹æ€§
        try:
            pil_image = Image.open(test_image_path)
            # ä¿®å¤PILå…¼å®¹æ€§é—®é¢˜
            if hasattr(Image, 'Resampling'):
                resized = pil_image.resize((200, 150), Image.Resampling.LANCZOS)
            else:
                try:
                    resized = pil_image.resize((200, 150), Image.ANTIALIAS)
                except AttributeError:
                    resized = pil_image.resize((200, 150))
            
            print(f"âœ… PILå›¾åƒå°ºå¯¸: {resized.size}")
            
        except Exception as e:
            print(f"âš ï¸ PILå¤„ç†è­¦å‘Š: {e}")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(test_image_path):
            os.remove(test_image_path)
        
        return True
        
    except Exception as e:
        print(f"âŒ å›¾åƒå¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_audio_processing():
    """æµ‹è¯•éŸ³é¢‘å¤„ç†åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•éŸ³é¢‘å¤„ç†åŠŸèƒ½...")
    
    try:
        # åˆ›å»ºæµ‹è¯•éŸ³é¢‘
        test_audio_path = "test_audio.wav"
        
        # ç”Ÿæˆ1ç§’çš„æµ‹è¯•éŸ³é¢‘
        sample_rate = 22050
        duration = 1.0
        t = np.linspace(0, duration, int(sample_rate * duration))
        audio = np.sin(2 * np.pi * 440 * t) * 0.3  # 440Hzæ­£å¼¦æ³¢
        
        # ä¿å­˜éŸ³é¢‘
        sf.write(test_audio_path, audio, sample_rate)
        
        # åŠ è½½éŸ³é¢‘
        y, sr = librosa.load(test_audio_path, sr=None)
        
        # æå–ç‰¹å¾
        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
        
        print(f"âœ… éŸ³é¢‘ä¿¡æ¯: æ—¶é•¿ {len(y)/sr:.2f}ç§’, é‡‡æ ·ç‡ {sr}Hz")
        print(f"âœ… èŠ‚æ‹: {tempo:.1f} BPM, æ£€æµ‹åˆ° {len(librosa.beat.beat_track(y=y, sr=sr)[1])} ä¸ªèŠ‚æ‹")
        print(f"âœ… é¢‘è°±è´¨å¿ƒ: {np.mean(spectral_centroids):.1f} Hz")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(test_audio_path):
            os.remove(test_audio_path)
        
        return True
        
    except Exception as e:
        print(f"âŒ éŸ³é¢‘å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_video_processing():
    """æµ‹è¯•è§†é¢‘å¤„ç†åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•è§†é¢‘å¤„ç†åŠŸèƒ½...")
    
    try:
        # åˆ›å»ºæµ‹è¯•è§†é¢‘
        test_video_path = "test_video.mp4"
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(test_video_path, fourcc, 10.0, (320, 240))
        
        # ç”Ÿæˆ20å¸§æµ‹è¯•è§†é¢‘
        for i in range(20):
            frame = np.random.randint(0, 255, (240, 320, 3), dtype=np.uint8)
            out.write(frame)
        
        out.release()
        
        # è¯»å–è§†é¢‘
        cap = cv2.VideoCapture(test_video_path)
        
        if cap.isOpened():
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            duration = frame_count / fps if fps > 0 else 0
            
            print(f"âœ… è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps:.1f}fps")
            print(f"âœ… æ€»å¸§æ•°: {frame_count}, æ—¶é•¿: {duration:.1f}ç§’")
            
            # è¯»å–ç¬¬ä¸€å¸§
            ret, frame = cap.read()
            if ret:
                print(f"âœ… æˆåŠŸè¯»å–ç¬¬ä¸€å¸§: {frame.shape}")
            
            cap.release()
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists(test_video_path):
            os.remove(test_video_path)
        
        return True
        
    except Exception as e:
        print(f"âŒ è§†é¢‘å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_text_embeddings():
    """æµ‹è¯•æ–‡æœ¬åµŒå…¥åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•æ–‡æœ¬åµŒå…¥åŠŸèƒ½...")
    
    try:
        # ä½¿ç”¨è½»é‡çº§æ¨¡å‹è¿›è¡Œæµ‹è¯•
        model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # æµ‹è¯•æ–‡æœ¬
        texts = ['Hello World', 'ä½ å¥½ä¸–ç•Œ', 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•']
        
        # ç”ŸæˆåµŒå…¥
        embeddings = model.encode(texts, show_progress_bar=True)
        
        print(f"âœ… åµŒå…¥ç»´åº¦: {embeddings.shape}")
        print(f"âœ… ç¬¬ä¸€ä¸ªå‘é‡: {embeddings[0][:5]}...")
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        from sklearn.metrics.pairwise import cosine_similarity
        similarity_matrix = cosine_similarity(embeddings)
        
        print("âœ… æ–‡æœ¬ç›¸ä¼¼åº¦çŸ©é˜µ:")
        for i, text1 in enumerate(texts):
            for j, text2 in enumerate(texts):
                sim = similarity_matrix[i][j]
                print(f"  '{text1}' vs '{text2}': {sim:.3f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ–‡æœ¬åµŒå…¥æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_faiss_integration():
    """æµ‹è¯•FAISSé›†æˆ (ä¿®å¤æ¥å£å…¼å®¹æ€§é—®é¢˜)"""
    print("\nğŸ” æµ‹è¯•FAISSé›†æˆ...")
    
    try:
        # ä½¿ç”¨è½»é‡çº§æ¨¡å‹
        model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        texts = [
            "è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£",
            "è¿™æ˜¯ç¬¬äºŒä¸ªæµ‹è¯•æ–‡æ¡£", 
            "è¿™æ˜¯ç¬¬ä¸‰ä¸ªæµ‹è¯•æ–‡æ¡£"
        ]
        
        # ç”ŸæˆåµŒå…¥
        embeddings = model.encode(texts)
        
        # åˆ›å»ºFAISSç´¢å¼•
        dimension = embeddings.shape[1]
        index = faiss.IndexFlatIP(dimension)
        
        # å½’ä¸€åŒ–å‘é‡
        faiss.normalize_L2(embeddings)
        
        # æ·»åŠ å‘é‡åˆ°ç´¢å¼•
        index.add(embeddings.astype('float32'))
        
        # æµ‹è¯•æœç´¢
        query = "æµ‹è¯•æ–‡æ¡£"
        query_embedding = model.encode([query])
        faiss.normalize_L2(query_embedding)
        
        scores, indices = index.search(query_embedding.astype('float32'), 3)
        
        print(f"âœ… FAISSç´¢å¼•åˆ›å»ºæˆåŠŸ: {dimension}ç»´, {len(texts)}ä¸ªæ–‡æ¡£")
        print(f"âœ… æœç´¢æµ‹è¯•æˆåŠŸ: æŸ¥è¯¢'{query}'")
        print(f"  ç»“æœ1: æ–‡æ¡£{indices[0][0]}, ç›¸ä¼¼åº¦: {scores[0][0]:.3f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ FAISSé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®ç›®å½•å’Œæ–‡ä»¶"""
    print("\nğŸ“ åˆ›å»ºç¤ºä¾‹æ•°æ®...")
    
    try:
        # åˆ›å»ºç›®å½•ç»“æ„
        directories = [
            "sample_docs/texts",
            "sample_docs/images", 
            "sample_docs/videos",
            "sample_docs/audios"
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
            print(f"âœ… åˆ›å»ºç›®å½•: {directory}")
        
        # åˆ›å»ºç¤ºä¾‹ä¸šåŠ¡æ–‡æ¡£
        business_docs = [
            ("sample_docs/texts/å•†ä¸šåˆåŒ.txt", "è¿™æ˜¯ä¸€ä»½æ ‡å‡†çš„å•†ä¸šåˆåŒæ¨¡æ¿ï¼ŒåŒ…å«ç”²ä¹™åŒæ–¹çš„æƒåˆ©ä¹‰åŠ¡æ¡æ¬¾ã€‚"),
            ("sample_docs/texts/è´¢åŠ¡æŠ¥è¡¨.txt", "2024å¹´åº¦è´¢åŠ¡æŠ¥è¡¨ï¼ŒåŒ…å«æ”¶å…¥ã€æ”¯å‡ºã€åˆ©æ¶¦ç­‰å…³é”®è´¢åŠ¡æŒ‡æ ‡ã€‚"),
            ("sample_docs/texts/äº§å“è¯´æ˜.txt", "äº§å“åŠŸèƒ½ç‰¹æ€§è¯´æ˜ï¼ŒåŒ…å«æŠ€æœ¯å‚æ•°ã€ä½¿ç”¨æ–¹æ³•ã€æ³¨æ„äº‹é¡¹ç­‰ã€‚")
        ]
        
        for file_path, content in business_docs:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… åˆ›å»ºç¤ºä¾‹ä¸šåŠ¡æ–‡æ¡£: {file_path}")
        
        # åˆ›å»ºå›¾åƒæè¿°æ–‡ä»¶
        image_descriptions = [
            ("sample_docs/images/äº§å“å›¾ç‰‡.txt", "äº§å“å¤–è§‚å±•ç¤ºå›¾ï¼ŒåŒ…å«äº§å“çš„ä¸»è¦ç‰¹å¾å’Œè®¾è®¡äº®ç‚¹ã€‚"),
            ("sample_docs/images/ç»„ç»‡ç»“æ„å›¾.txt", "å…¬å¸ç»„ç»‡æ¶æ„å›¾ï¼Œå±•ç¤ºå„éƒ¨é—¨çš„å±‚çº§å…³ç³»å’ŒèŒè´£åˆ†å·¥ã€‚")
        ]
        
        for file_path, content in image_descriptions:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… åˆ›å»ºå›¾åƒæè¿°æ–‡ä»¶: {file_path}")
        
        # åˆ›å»ºè§†é¢‘æè¿°æ–‡ä»¶
        video_descriptions = [
            ("sample_docs/videos/ä¼šè®®è®°å½•.txt", "é‡è¦ä¼šè®®çš„è§†é¢‘è®°å½•ï¼ŒåŒ…å«ä¼šè®®è®®ç¨‹ã€è®¨è®ºå†…å®¹å’Œå†³è®®äº‹é¡¹ã€‚"),
            ("sample_docs/videos/äº§å“æ¼”ç¤º.txt", "äº§å“åŠŸèƒ½æ¼”ç¤ºè§†é¢‘ï¼Œå±•ç¤ºäº§å“çš„ä½¿ç”¨æ–¹æ³•å’Œåº”ç”¨åœºæ™¯ã€‚")
        ]
        
        for file_path, content in video_descriptions:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… åˆ›å»ºè§†é¢‘æè¿°æ–‡ä»¶: {file_path}")
        
        # åˆ›å»ºéŸ³é¢‘æè¿°æ–‡ä»¶
        audio_descriptions = [
            ("sample_docs/audios/ä¼šè®®å½•éŸ³.txt", "ä¼šè®®éŸ³é¢‘è®°å½•ï¼ŒåŒ…å«å‘è¨€äººçš„è®²è¯å†…å®¹å’Œè®¨è®ºè¿‡ç¨‹ã€‚"),
            ("sample_docs/audios/åŸ¹è®­è¯¾ç¨‹.txt", "å‘˜å·¥åŸ¹è®­è¯¾ç¨‹å½•éŸ³ï¼ŒåŒ…å«ä¸“ä¸šçŸ¥è¯†è®²è§£å’Œæ¡ˆä¾‹åˆ†æã€‚")
        ]
        
        for file_path, content in audio_descriptions:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… åˆ›å»ºéŸ³é¢‘æè¿°æ–‡ä»¶: {file_path}")
        
        print("âœ… ç¤ºä¾‹æ•°æ®åˆ›å»ºå®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºç¤ºä¾‹æ•°æ®å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¤šæ¨¡æ€å‘é‡åŒ–ç³»ç»ŸåŠŸèƒ½æµ‹è¯• (ä¿®å¤ç‰ˆæœ¬)")
    print("=" * 60)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_results = []
    
    test_results.append(("ç¯å¢ƒä¾èµ–", test_environment()))
    test_results.append(("OCRåŠŸèƒ½", test_ocr_functionality()))
    test_results.append(("å›¾åƒå¤„ç†", test_image_processing()))
    test_results.append(("éŸ³é¢‘å¤„ç†", test_audio_processing()))
    test_results.append(("è§†é¢‘å¤„ç†", test_video_processing()))
    test_results.append(("æ–‡æœ¬åµŒå…¥", test_text_embeddings()))
    test_results.append(("FAISSé›†æˆ", test_faiss_integration()))
    test_results.append(("ç¤ºä¾‹æ•°æ®", create_sample_data()))
    
    # æ±‡æ€»æµ‹è¯•ç»“æœ
    print("\nğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    print("=" * 60)
    
    passed = 0
    failed = 0
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name:<15} : {status}")
        if result:
            passed += 1
        else:
            failed += 1
    
    print("=" * 60)
    print(f"æ€»æµ‹è¯•æ•°: {len(test_results)}, é€šè¿‡: {passed}, å¤±è´¥: {failed}")
    
    if failed > 0:
        print(f"\nâš ï¸ æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³ä¾èµ–")
    else:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå·²å°±ç»ª")
    
    print(f"\nğŸš€ ç°åœ¨å¯ä»¥è¿è¡Œå¤šæ¨¡æ€å‘é‡åŒ–ç³»ç»Ÿäº†ï¼")
    print("è¿è¡Œå‘½ä»¤: python multimodal_vectorizer_fixed.py")

if __name__ == "__main__":
    main()

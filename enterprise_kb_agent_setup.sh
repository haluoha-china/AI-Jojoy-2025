#!/bin/bash
# ä¼ä¸šçŸ¥è¯†åº“ åƒé—®Agentç‰ˆæœ¬ä¸€é”®éƒ¨ç½²è„šæœ¬
# é€‚ç”¨ï¼šRTX 4090 24GB + Ubuntu 22.04 + AutoDLçŽ¯å¢ƒ
# åŠŸèƒ½ï¼šåƒé—®Agent + Function Call + çŸ¥è¯†åº“æœåŠ¡ + 7B LoRAå¾®è°ƒ + å¤šæ¨¡æ€æ¨¡åž‹
# æž¶æž„ï¼šç”¨æˆ·é—®é¢˜ â†’ åƒé—®Agent â†’ Function Call â†’ çŸ¥è¯†åº“æœåŠ¡ â†’ è¿”å›žç»“æžœ
# å­˜å‚¨ä¼˜åŒ–ï¼šç³»ç»Ÿç›˜(50G) + æ•°æ®ç›˜(400G)
set -e

echo "ðŸš€ å¼€å§‹éƒ¨ç½²ä¼ä¸šçŸ¥è¯†åº“ç³»ç»Ÿï¼ˆåƒé—®Agentç‰ˆæœ¬ï¼‰..."

# ====== 0) æ£€æµ‹å­˜å‚¨ç©ºé—´å’Œé…ç½®æ•°æ®ç›˜ ======
echo "ðŸ’¾ æ£€æµ‹å­˜å‚¨ç©ºé—´..."

# æ£€æµ‹æ•°æ®ç›˜
DATA_DISK=$(df -h | grep -E '/root/autodl-tmp|/data|/mnt' | head -1 | awk '{print $6}')
if [ -z "$DATA_DISK" ]; then
    DATA_DISK="/root/autodl-tmp"
fi

echo "ðŸ“ æ•°æ®ç›˜è·¯å¾„: $DATA_DISK"
echo "ðŸ’¾ æ•°æ®ç›˜ç©ºé—´: $(df -h $DATA_DISK | tail -1 | awk '{print $4}')"

# æ£€æŸ¥ç³»ç»Ÿç›˜ç©ºé—´
SYSTEM_SPACE=$(df -h / | tail -1 | awk '{print $4}')
echo "ðŸ’¾ ç³»ç»Ÿç›˜å‰©ä½™ç©ºé—´: $SYSTEM_SPACE"

# åˆ›å»ºæ•°æ®ç›˜ç›®å½•ç»“æž„
mkdir -p $DATA_DISK/enterprise_kb/{models,data,vector_db,documents}
echo "âœ… æ•°æ®ç›˜ç›®å½•ç»“æž„åˆ›å»ºå®Œæˆ"

# è®¾ç½®çŽ¯å¢ƒå˜é‡ï¼Œå°†æ¨¡åž‹ç¼“å­˜æŒ‡å‘æ•°æ®ç›˜
export TRANSFORMERS_CACHE="$DATA_DISK/enterprise_kb/models/transformers"
export HF_HOME="$DATA_DISK/enterprise_kb/models/huggingface"
export TORCH_HOME="$DATA_DISK/enterprise_kb/models/torch"

echo "ðŸ”§ æ¨¡åž‹ç¼“å­˜è·¯å¾„é…ç½®å®Œæˆï¼š"
echo "   Transformers: $TRANSFORMERS_CACHE"
echo "   HuggingFace: $HF_HOME"
echo "   PyTorch: $TORCH_HOME"

# ====== 1) ç³»ç»ŸåŸºç¡€çŽ¯å¢ƒ ======
echo "ðŸ“¦ å®‰è£…ç³»ç»Ÿä¾èµ–..."
apt update -y
apt install -y python3-pip python3-venv git build-essential curl wget

# ====== 2) åˆ›å»ºPythonè™šæ‹ŸçŽ¯å¢ƒï¼ˆç³»ç»Ÿç›˜ï¼‰ ======
echo "ðŸ åˆ›å»ºPythonè™šæ‹ŸçŽ¯å¢ƒ..."
cd ~
python3 -m venv enterprise_kb_env
source enterprise_kb_env/bin/activate

# éªŒè¯PythonçŽ¯å¢ƒ
echo "âœ… Pythonç‰ˆæœ¬: $(python --version)"
echo "âœ… Pipç‰ˆæœ¬: $(pip --version)"

# ====== 3) å®‰è£…æ ¸å¿ƒAIåº“ï¼ˆé…ç½®åˆ°æ•°æ®ç›˜ï¼‰ ======
echo "ðŸ¤– å®‰è£…æ ¸å¿ƒAIåº“..."

# å®‰è£…PyTorchï¼ˆä½¿ç”¨æ¸…åŽé•œåƒæºï¼‰
echo "ðŸ“¥ å®‰è£…PyTorch (çº¦2-3GB)..."
pip install torch torchvision torchaudio --index-url https://pypi.tuna.tsinghua.edu.cn/simple

# å®‰è£…Transformerså’ŒEmbeddingåº“
echo "ðŸ“¥ å®‰è£…Transformers (çº¦1-2GB)..."
pip install transformers sentence-transformers --index-url https://pypi.tuna.tsinghua.edu.cn/simple

# å®‰è£…Milvus Pythonå®¢æˆ·ç«¯
echo "ðŸ“¥ å®‰è£…Milvuså®¢æˆ·ç«¯..."
pip install pymilvus --index-url https://pypi.tuna.tsinghua.edu.cn/simple

# ====== 4) å®‰è£…æ–‡æ¡£å¤„ç†åº“ ======
echo "ðŸ“„ å®‰è£…æ–‡æ¡£å¤„ç†åº“..."

# å®‰è£…æ–‡æ¡£å¤„ç†åº“
pip install PyMuPDF pypdf2 pdfplumber --index-url https://pypi.tuna.tsinghua.edu.cn/simple

# å®‰è£…OCRåº“
echo "ðŸ“¥ å®‰è£…PaddleOCR (çº¦1-2GB)..."
pip install paddlepaddle paddleocr --index-url https://pypi.tuna.tsinghua.edu.cn/simple

# å®‰è£…å›¾åƒå¤„ç†åº“
pip install opencv-python Pillow --index-url https://pypi.tuna.tsinghua.edu.cn/simple

# ====== 5) å®‰è£…Webæ¡†æž¶å’Œå·¥å…·åº“ ======
echo "ðŸŒ å®‰è£…Webæ¡†æž¶..."
# å®‰è£…FastAPIå’Œå·¥å…·åº“
pip install fastapi uvicorn python-multipart --index-url https://pypi.tuna.tsinghua.edu.cn/simple

# å®‰è£…å…¶ä»–å·¥å…·åº“
pip install requests tqdm python-dotenv pydantic --index-url https://pypi.tuna.tsinghua.edu.cn/simple

# ====== 6) 7B LoRA å¾®è°ƒçŽ¯å¢ƒï¼ˆæ•°æ®ç›˜ï¼‰ ======
echo "ðŸ¤– å‡†å¤‡ 7B LoRA å¾®è°ƒçŽ¯å¢ƒ..."
cd $DATA_DISK/enterprise_kb
if [ ! -d "LLaMA-Factory" ]; then
    echo "ðŸ“¥ å…‹éš†LLaMA-Factoryåˆ°æ•°æ®ç›˜..."
    git clone https://github.com/hiyouga/LLaMA-Factory.git
fi
cd LLaMA-Factory

# å®‰è£…LLaMA-Factoryä¾èµ–
echo "ðŸ“¥ å®‰è£…LLaMA-Factoryä¾èµ–..."
pip install -r requirements.txt --index-url https://pypi.tuna.tsinghua.edu.cn/simple

# å‡†å¤‡ä¼ä¸šçŸ¥è¯†åº“è®­ç»ƒæ•°æ®
mkdir -p data
cat > data/enterprise_kb.jsonl <<EOF
{"instruction":"ESSåŸ¹è®­æ¯æœˆå‡ æ¬¡ï¼Ÿ","input":"","output":"æ ¹æ®ã€ŠESSåŸ¹è®­ç®¡ç†åˆ¶åº¦ã€‹è§„å®šï¼ŒESSåŸ¹è®­æ¯æœˆè¿›è¡Œ3æ¬¡ï¼Œåˆ†åˆ«åœ¨æ¯æœˆç¬¬ä¸€å‘¨ã€ç¬¬ä¸‰å‘¨å’Œç¬¬äº”å‘¨è¿›è¡Œã€‚å…·ä½“æ—¶é—´å®‰æŽ’è¯·æŸ¥çœ‹å…¬å¸å†…ç½‘åŸ¹è®­æ—¥åŽ†ã€‚"}
{"instruction":"æ‰“å°æœºå‡ºçŽ°æ•°æ®åº“è¿žæŽ¥å¤±è´¥æ€Žä¹ˆåŠžï¼Ÿ","input":"","output":"å½“æ‰“å°æœºå‡ºçŽ°æ•°æ®åº“è¿žæŽ¥å¤±è´¥æ—¶ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤å¤„ç†ï¼š1. æ£€æŸ¥MSSQLSERVERæœåŠ¡æ˜¯å¦å¯åŠ¨ï¼›2. ç¡®è®¤1433ç«¯å£æ˜¯å¦æ”¾è¡Œï¼›3. æ£€æŸ¥ç½‘ç»œè¿žæŽ¥ï¼›4. é‡å¯æ‰“å°æœåŠ¡ã€‚è¯¦ç»†æ“ä½œæ­¥éª¤è¯·å‚è€ƒã€ŠITæ•…éšœå¤„ç†æ‰‹å†Œã€‹ç¬¬12é¡µã€‚"}
{"instruction":"ä»€ä¹ˆæ˜¯ESSç³»ç»Ÿï¼Ÿ","input":"","output":"ESSï¼ˆEmployee Self Serviceï¼‰æ˜¯å‘˜å·¥è‡ªåŠ©æœåŠ¡ç³»ç»Ÿï¼Œå‘˜å·¥å¯ä»¥é€šè¿‡è¯¥ç³»ç»Ÿè¿›è¡Œè¯·å‡ç”³è¯·ã€åŠ ç­ç”³è¯·ã€è€ƒå‹¤æŸ¥è¯¢ã€è–ªèµ„æŸ¥è¯¢ç­‰æ“ä½œã€‚ç³»ç»Ÿè®¿é—®åœ°å€ï¼šhttp://ess.company.com"}
{"instruction":"å…¬å¸å†…éƒ¨ç®€ç§°è§£é‡Š","input":"","output":"å…¬å¸å†…éƒ¨å¸¸ç”¨ç®€ç§°åŒ…æ‹¬ï¼šESSï¼ˆå‘˜å·¥è‡ªåŠ©æœåŠ¡ï¼‰ã€OAï¼ˆåŠžå…¬è‡ªåŠ¨åŒ–ï¼‰ã€ERPï¼ˆä¼ä¸šèµ„æºè§„åˆ’ï¼‰ã€CRMï¼ˆå®¢æˆ·å…³ç³»ç®¡ç†ï¼‰ã€HRï¼ˆäººåŠ›èµ„æºï¼‰ã€ITï¼ˆä¿¡æ¯æŠ€æœ¯ï¼‰ã€QAï¼ˆè´¨é‡ä¿è¯ï¼‰ã€QCï¼ˆè´¨é‡æŽ§åˆ¶ï¼‰ç­‰ã€‚"}
{"instruction":"å¦‚ä½•ç”³è¯·å¹´å‡ï¼Ÿ","input":"","output":"å¹´å‡ç”³è¯·æµç¨‹ï¼š1. ç™»å½•ESSç³»ç»Ÿï¼›2. é€‰æ‹©'è¯·å‡ç”³è¯·'ï¼›3. å¡«å†™è¯·å‡ç±»åž‹ä¸º'å¹´å‡'ï¼›4. é€‰æ‹©å¼€å§‹å’Œç»“æŸæ—¶é—´ï¼›5. å¡«å†™è¯·å‡äº‹ç”±ï¼›6. æäº¤ç”³è¯·ç­‰å¾…å®¡æ‰¹ã€‚è¯¦ç»†æ“ä½œæ­¥éª¤è¯·å‚è€ƒã€ŠESSç³»ç»Ÿä½¿ç”¨æ‰‹å†Œã€‹ã€‚"}
EOF

echo "ðŸ“š è®­ç»ƒæ•°æ®å·²å‡†å¤‡å®Œæˆï¼ŒåŒ…å«ä¼ä¸šçŸ¥è¯†åº“æ ·æœ¬..."

# ====== 7) åˆ›å»ºçŸ¥è¯†åº“æœåŠ¡ç›®å½•ï¼ˆç³»ç»Ÿç›˜ï¼‰ ======
echo "ðŸ“ åˆ›å»ºçŸ¥è¯†åº“æœåŠ¡ç›®å½•..."
cd ~
mkdir -p enterprise_kb_service
cd enterprise_kb_service

# åˆ›å»ºé¡¹ç›®ç»“æž„
mkdir -p {api,core,utils,data,logs}

# ====== 8) åˆ›å»ºæ ¸å¿ƒé…ç½®æ–‡ä»¶ ======
echo "âš™ï¸ åˆ›å»ºæ ¸å¿ƒé…ç½®æ–‡ä»¶..."

# åˆ›å»ºrequirements.txt
cat > requirements.txt <<EOF
fastapi==0.104.1
uvicorn==0.24.0
python-multipart==0.0.6
pydantic==2.5.0
torch>=2.0.0
transformers>=4.30.0
sentence-transformers>=2.2.0
pymilvus>=2.3.0
PyMuPDF>=1.23.0
paddlepaddle>=2.5.0
paddleocr>=2.7.0
opencv-python>=4.8.0
Pillow>=9.5.0
python-dotenv>=1.0.0
requests>=2.31.0
tqdm>=4.65.0
EOF

# åˆ›å»ºçŽ¯å¢ƒé…ç½®æ–‡ä»¶ï¼ˆåŒ…å«æ•°æ®ç›˜è·¯å¾„ï¼‰
cat > .env <<EOF
# çŸ¥è¯†åº“æœåŠ¡é…ç½®
MILVUS_HOST=localhost
MILVUS_PORT=19530
EMBEDDING_MODEL=BAAI/bge-large-zh
API_HOST=0.0.0.0
API_PORT=8000

# åƒé—®Agenté…ç½®
QWEN_API_KEY=your_api_key_here
QWEN_API_BASE=https://dashscope.aliyun.com/api/v1

# å­˜å‚¨è·¯å¾„é…ç½®
DATA_DISK=$DATA_DISK
TRANSFORMERS_CACHE=$DATA_DISK/enterprise_kb/models/transformers
HF_HOME=$DATA_DISK/enterprise_kb/models/huggingface
TORCH_HOME=$DATA_DISK/enterprise_kb/models/torch
VECTOR_DB_PATH=$DATA_DISK/enterprise_kb/vector_db
DOCUMENTS_PATH=$DATA_DISK/enterprise_kb/documents
TRAINING_DATA_PATH=$DATA_DISK/enterprise_kb/data

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FILE=logs/enterprise_kb.log
EOF

# ====== 9) åˆ›å»ºFunction CallæŽ¥å£ ======
echo "ðŸ”§ åˆ›å»ºFunction CallæŽ¥å£..."

# åˆ›å»ºä¸»APIæ–‡ä»¶
cat > api/main.py <<EOF
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.knowledge_base import KnowledgeBaseService
from core.document_parser import DocumentParser
from core.multimodal_processor import MultimodalProcessor

app = FastAPI(title="ä¼ä¸šçŸ¥è¯†åº“Function Call API", version="1.0.0")

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# åˆå§‹åŒ–æœåŠ¡
kb_service = KnowledgeBaseService()
doc_parser = DocumentParser()
mm_processor = MultimodalProcessor()

class SearchRequest(BaseModel):
    query: str
    top_k: int = 5

@app.get("/")
async def root():
    return {"message": "ä¼ä¸šçŸ¥è¯†åº“Function Call API", "status": "running"}

@app.post("/api/search")
async def search_knowledge_base(request: SearchRequest):
    """æœç´¢çŸ¥è¯†åº“å†…å®¹ - ä¾›åƒé—®Agentè°ƒç”¨"""
    try:
        results = kb_service.search(request.query, request.top_k)
        return {"success": True, "data": results}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/parse_document")
async def parse_document(file: UploadFile = File(...)):
    """è§£æžä¸Šä¼ çš„æ–‡æ¡£ - ä¾›åƒé—®Agentè°ƒç”¨"""
    try:
        content = doc_parser.parse_file(file)
        return {"success": True, "data": content}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/process_multimodal")
async def process_multimodal(content: str, file_type: str):
    """å¤„ç†å¤šæ¨¡æ€å†…å®¹ - ä¾›åƒé—®Agentè°ƒç”¨"""
    try:
        result = mm_processor.process(content, file_type)
        return {"success": True, "data": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æŽ¥å£"""
    return {"status": "healthy", "service": "enterprise_kb"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
EOF

# ====== 10) åˆ›å»ºæ ¸å¿ƒæœåŠ¡æ¨¡å— ======
echo "ðŸ§  åˆ›å»ºæ ¸å¿ƒæœåŠ¡æ¨¡å—..."

# åˆ›å»ºçŸ¥è¯†åº“æœåŠ¡
cat > core/knowledge_base.py <<EOF
import os
import sys
from typing import List, Dict, Any
from pymilvus import connections, Collection, utility
from sentence_transformers import SentenceTransformer
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class KnowledgeBaseService:
    def __init__(self):
        self.embedding_model = None
        self.collection = None
        self._init_services()
    
    def _init_services(self):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“å’ŒEmbeddingæ¨¡åž‹"""
        try:
            # è¿žæŽ¥Milvus
            connections.connect("default", host="localhost", port="19530")
            logger.info("âœ… æˆåŠŸè¿žæŽ¥Milvuså‘é‡æ•°æ®åº“")
            
            # åŠ è½½Embeddingæ¨¡åž‹
            self.embedding_model = SentenceTransformer('BAAI/bge-large-zh')
            logger.info("âœ… æˆåŠŸåŠ è½½BGE Embeddingæ¨¡åž‹")
            
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–æœåŠ¡å¤±è´¥: {e}")
            raise
    
    def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢çŸ¥è¯†åº“"""
        try:
            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_vector = self.embedding_model.encode([query])
            
            # æ‰§è¡Œå‘é‡æœç´¢
            # è¿™é‡Œéœ€è¦æ ¹æ®å®žé™…çš„Milvusé›†åˆç»“æž„æ¥å®žçŽ°
            # æš‚æ—¶è¿”å›žæ¨¡æ‹Ÿç»“æžœ
            results = [
                {
                    "content": f"å…³äºŽ'{query}'çš„æœç´¢ç»“æžœ1",
                    "score": 0.95,
                    "source": "ä¼ä¸šçŸ¥è¯†åº“æ–‡æ¡£1"
                },
                {
                    "content": f"å…³äºŽ'{query}'çš„æœç´¢ç»“æžœ2", 
                    "score": 0.88,
                    "source": "ä¼ä¸šçŸ¥è¯†åº“æ–‡æ¡£2"
                }
            ]
            
            return results[:top_k]
            
        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}")
            raise
    
    def add_document(self, content: str, metadata: Dict[str, Any]):
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        try:
            # ç”Ÿæˆæ–‡æ¡£å‘é‡
            doc_vector = self.embedding_model.encode([content])
            
            # å­˜å‚¨åˆ°Milvus
            # è¿™é‡Œéœ€è¦æ ¹æ®å®žé™…çš„Milvusé›†åˆç»“æž„æ¥å®žçŽ°
            logger.info(f"âœ… æˆåŠŸæ·»åŠ æ–‡æ¡£: {metadata.get('title', 'Unknown')}")
            
        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            raise
EOF

# åˆ›å»ºæ–‡æ¡£è§£æžå™¨
cat > core/document_parser.py <<EOF
import fitz  # PyMuPDF
import logging
from typing import Dict, Any
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DocumentParser:
    def __init__(self):
        self.supported_formats = ['.pdf', '.txt', '.docx']
    
    def parse_file(self, file) -> Dict[str, Any]:
        """è§£æžä¸Šä¼ çš„æ–‡ä»¶"""
        try:
            file_extension = os.path.splitext(file.filename)[1].lower()
            
            if file_extension == '.pdf':
                return self._parse_pdf(file)
            elif file_extension == '.txt':
                return self._parse_txt(file)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_extension}")
                
        except Exception as e:
            logger.error(f"æ–‡ä»¶è§£æžå¤±è´¥: {e}")
            raise
    
    def _parse_pdf(self, file) -> Dict[str, Any]:
        """è§£æžPDFæ–‡ä»¶"""
        try:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            file_path = f"/tmp/{file.filename}"
            with open(file_path, "wb") as buffer:
                buffer.write(file.file.read())
            
            # ä½¿ç”¨PyMuPDFè§£æž
            doc = fitz.open(file_path)
            text_content = ""
            
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                text_content += page.get_text()
            
            doc.close()
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.remove(file_path)
            
            return {
                "content": text_content,
                "pages": len(doc),
                "format": "PDF",
                "filename": file.filename
            }
            
        except Exception as e:
            logger.error(f"PDFè§£æžå¤±è´¥: {e}")
            raise
    
    def _parse_txt(self, file) -> Dict[str, Any]:
        """è§£æžTXTæ–‡ä»¶"""
        try:
            content = file.file.read().decode('utf-8')
            
            return {
                "content": content,
                "format": "TXT",
                "filename": file.filename
            }
            
        except Exception as e:
            logger.error(f"TXTè§£æžå¤±è´¥: {e}")
            raise
EOF

# åˆ›å»ºå¤šæ¨¡æ€å¤„ç†å™¨
cat > core/multimodal_processor.py <<EOF
import logging
from typing import Dict, Any
import cv2
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MultimodalProcessor:
    def __init__(self):
        self.supported_types = ['image', 'video', 'text']
    
    def process(self, content: str, file_type: str) -> Dict[str, Any]:
        """å¤„ç†å¤šæ¨¡æ€å†…å®¹"""
        try:
            if file_type == 'image':
                return self._process_image(content)
            elif file_type == 'video':
                return self._process_video(content)
            elif file_type == 'text':
                return self._process_text(content)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»åž‹: {file_type}")
                
        except Exception as e:
            logger.error(f"å¤šæ¨¡æ€å¤„ç†å¤±è´¥: {e}")
            raise
    
    def _process_image(self, content: str) -> Dict[str, Any]:
        """å¤„ç†å›¾åƒå†…å®¹"""
        try:
            # è¿™é‡Œå¯ä»¥é›†æˆå›¾åƒç†è§£æ¨¡åž‹
            # æš‚æ—¶è¿”å›žåŸºç¡€ä¿¡æ¯
            return {
                "type": "image",
                "content": content,
                "analysis": "å›¾åƒå†…å®¹åˆ†æžç»“æžœ",
                "status": "processed"
            }
            
        except Exception as e:
            logger.error(f"å›¾åƒå¤„ç†å¤±è´¥: {e}")
            raise
    
    def _process_video(self, content: str) -> Dict[str, Any]:
        """å¤„ç†è§†é¢‘å†…å®¹"""
        try:
            # è¿™é‡Œå¯ä»¥é›†æˆè§†é¢‘ç†è§£æ¨¡åž‹
            # æš‚æ—¶è¿”å›žåŸºç¡€ä¿¡æ¯
            return {
                "type": "video",
                "content": content,
                "analysis": "è§†é¢‘å†…å®¹åˆ†æžç»“æžœ",
                "status": "processed"
            }
            
        except Exception as e:
            logger.error(f"è§†é¢‘å¤„ç†å¤±è´¥: {e}")
            raise
    
    def _process_text(self, content: str) -> Dict[str, Any]:
        """å¤„ç†æ–‡æœ¬å†…å®¹"""
        try:
            return {
                "type": "text",
                "content": content,
                "analysis": "æ–‡æœ¬å†…å®¹åˆ†æžç»“æžœ",
                "status": "processed"
            }
            
        except Exception as e:
            logger.error(f"æ–‡æœ¬å¤„ç†å¤±è´¥: {e}")
            raise
EOF

# ====== 11) åˆ›å»ºå¯åŠ¨è„šæœ¬ ======
echo "ðŸš€ åˆ›å»ºå¯åŠ¨è„šæœ¬..."

# åˆ›å»ºå¯åŠ¨è„šæœ¬
cat > start_service.sh <<EOF
#!/bin/bash
echo "ðŸš€ å¯åŠ¨ä¼ä¸šçŸ¥è¯†åº“æœåŠ¡..."

# æ¿€æ´»è™šæ‹ŸçŽ¯å¢ƒ
source ~/enterprise_kb_env/bin/activate

# è®¾ç½®çŽ¯å¢ƒå˜é‡
export TRANSFORMERS_CACHE="$DATA_DISK/enterprise_kb/models/transformers"
export HF_HOME="$DATA_DISK/enterprise_kb/models/huggingface"
export TORCH_HOME="$DATA_DISK/enterprise_kb/models/torch"

# è¿›å…¥æœåŠ¡ç›®å½•
cd ~/enterprise_kb_service

# å¯åŠ¨APIæœåŠ¡
echo "ðŸŒ å¯åŠ¨Function Call APIæœåŠ¡..."
python api/main.py
EOF

chmod +x start_service.sh

# ====== 12) åˆ›å»ºåƒé—®Agenté…ç½®ç¤ºä¾‹ ======
echo "ðŸ¤– åˆ›å»ºåƒé—®Agenté…ç½®ç¤ºä¾‹..."

cat > qwen_agent_config.md <<EOF
# åƒé—®Agenté…ç½®æŒ‡å—

## Function Callé…ç½®

åœ¨åƒé—®Agentä¸­é…ç½®ä»¥ä¸‹Functionï¼š

### 1. æœç´¢çŸ¥è¯†åº“
\`\`\`json
{
  "name": "search_knowledge_base",
  "description": "æœç´¢ä¼ä¸šçŸ¥è¯†åº“å†…å®¹",
  "parameters": {
    "type": "object",
    "properties": {
      "query": {
        "type": "string",
        "description": "æœç´¢æŸ¥è¯¢å†…å®¹"
      },
      "top_k": {
        "type": "integer",
        "description": "è¿”å›žç»“æžœæ•°é‡ï¼Œé»˜è®¤5"
      }
    },
    "required": ["query"]
  }
}
\`\`\`

### 2. è§£æžæ–‡æ¡£
\`\`\`json
{
  "name": "parse_document",
  "description": "è§£æžä¸Šä¼ çš„ä¼ä¸šæ–‡æ¡£",
  "parameters": {
    "type": "object",
    "properties": {
      "file": {
        "type": "string",
        "description": "æ–‡ä»¶è·¯å¾„æˆ–å†…å®¹"
      }
    },
    "required": ["file"]
  }
}
\`\`\`

### 3. å¤„ç†å¤šæ¨¡æ€å†…å®¹
\`\`\`json
{
  "name": "process_multimodal",
  "description": "å¤„ç†å¤šæ¨¡æ€å†…å®¹ï¼ˆå›¾ç‰‡ã€è§†é¢‘ã€æ–‡æœ¬ï¼‰",
  "parameters": {
    "type": "object",
    "properties": {
      "content": {
        "type": "string",
        "description": "å†…å®¹æè¿°"
      },
      "file_type": {
        "type": "string",
        "enum": ["image", "video", "text"],
        "description": "æ–‡ä»¶ç±»åž‹"
      }
    },
    "required": ["content", "file_type"]
  }
}
\`\`\`

## APIç«¯ç‚¹

- æœç´¢çŸ¥è¯†åº“: POST /api/search
- è§£æžæ–‡æ¡£: POST /api/parse_document  
- å¤„ç†å¤šæ¨¡æ€: POST /api/process_multimodal
- å¥åº·æ£€æŸ¥: GET /api/health

## ä½¿ç”¨ç¤ºä¾‹

ç”¨æˆ·: "å¸®æˆ‘æœç´¢ä¸€ä¸‹ESSåŸ¹è®­ç›¸å…³çš„ä¿¡æ¯"
Agent: è°ƒç”¨search_knowledge_baseå‡½æ•°ï¼ŒæŸ¥è¯¢"ESSåŸ¹è®­"
ç»“æžœ: è¿”å›žç›¸å…³æ–‡æ¡£å†…å®¹å’Œæ¥æº
EOF

# ====== 13) åˆ›å»ºå­˜å‚¨ç©ºé—´ä½¿ç”¨è¯´æ˜Ž ======
echo "ðŸ“‹ åˆ›å»ºå­˜å‚¨ç©ºé—´ä½¿ç”¨è¯´æ˜Ž..."

cat > storage_usage.md <<EOF
# å­˜å‚¨ç©ºé—´ä½¿ç”¨è¯´æ˜Ž

## å­˜å‚¨åˆ†é…

### ç³»ç»Ÿç›˜ (50G)
- Pythonè™šæ‹ŸçŽ¯å¢ƒ: ~/enterprise_kb_env/ (~2-3GB)
- é¡¹ç›®ä»£ç : ~/enterprise_kb_service/ (~100MB)
- ç³»ç»Ÿä¾èµ–: ~1-2GB
- **æ€»è®¡: ~5-6GB**

### æ•°æ®ç›˜ (400G)
- æ¨¡åž‹æ–‡ä»¶: $DATA_DISK/enterprise_kb/models/ (~20-30GB)
- è®­ç»ƒæ•°æ®: $DATA_DISK/enterprise_kb/data/ (~1-5GB)
- å‘é‡æ•°æ®åº“: $DATA_DISK/enterprise_kb/vector_db/ (~10-50GB)
- ä¼ä¸šæ–‡æ¡£: $DATA_DISK/enterprise_kb/documents/ (~10-100GB)
- **æ€»è®¡: ~40-185GB**

## çŽ¯å¢ƒå˜é‡é…ç½®
\`\`\`bash
export TRANSFORMERS_CACHE="$DATA_DISK/enterprise_kb/models/transformers"
export HF_HOME="$DATA_DISK/enterprise_kb/models/huggingface"
export TORCH_HOME="$DATA_DISK/enterprise_kb/models/torch"
\`\`\`

## ç›®å½•ç»“æž„
\`\`\`
$DATA_DISK/enterprise_kb/
â”œâ”€â”€ models/                   # æ¨¡åž‹æ–‡ä»¶
â”‚   â”œâ”€â”€ transformers/        # Transformersç¼“å­˜
â”‚   â”œâ”€â”€ huggingface/         # HuggingFaceç¼“å­˜
â”‚   â””â”€â”€ torch/               # PyTorchç¼“å­˜
â”œâ”€â”€ data/                    # è®­ç»ƒæ•°æ®
â”œâ”€â”€ vector_db/               # å‘é‡æ•°æ®åº“
â””â”€â”€ documents/               # ä¼ä¸šæ–‡æ¡£
    â”œâ”€â”€ pdf/
    â”œâ”€â”€ images/
    â””â”€â”€ videos/
\`\`\`
EOF

# ====== 14) éªŒè¯å®‰è£… ======
echo "âœ… éªŒè¯å®‰è£…..."

# æ£€æŸ¥PythonåŒ…
echo "ðŸ” æ£€æŸ¥å·²å®‰è£…çš„PythonåŒ…..."
pip list | grep -E "(torch|transformers|sentence-transformers|pymilvus|PyMuPDF|fastapi)"

# æ£€æŸ¥ç›®å½•ç»“æž„
echo "ðŸ“ æ£€æŸ¥é¡¹ç›®ç›®å½•ç»“æž„..."
ls -la ~/enterprise_kb_service/
echo "ðŸ“ æ£€æŸ¥æ•°æ®ç›˜ç›®å½•ç»“æž„..."
ls -la $DATA_DISK/enterprise_kb/

# æ£€æŸ¥å­˜å‚¨ç©ºé—´ä½¿ç”¨
echo "ðŸ’¾ æ£€æŸ¥å­˜å‚¨ç©ºé—´ä½¿ç”¨..."
echo "ç³»ç»Ÿç›˜ä½¿ç”¨:"
df -h / | tail -1
echo "æ•°æ®ç›˜ä½¿ç”¨:"
df -h $DATA_DISK | tail -1

echo ""
echo "ðŸŽ‰ ä¼ä¸šçŸ¥è¯†åº“ç³»ç»Ÿï¼ˆåƒé—®Agentç‰ˆæœ¬ï¼‰éƒ¨ç½²å®Œæˆï¼"
echo ""
echo "ðŸ“‹ ç³»ç»Ÿæž¶æž„ï¼š"
echo "   ç”¨æˆ·é—®é¢˜ â†’ åƒé—®Agent â†’ Function Call â†’ çŸ¥è¯†åº“æœåŠ¡ â†’ è¿”å›žç»“æžœ"
echo ""
echo "ðŸ“ é¡¹ç›®ç›®å½•ï¼š~/enterprise_kb_service/"
echo "ðŸ PythonçŽ¯å¢ƒï¼š~/enterprise_kb_env/"
echo "ðŸš€ å¯åŠ¨è„šæœ¬ï¼š~/enterprise_kb_service/start_service.sh"
echo ""
echo "ðŸ’¾ å­˜å‚¨ä¼˜åŒ–ï¼š"
echo "   ç³»ç»Ÿç›˜: ~5-6GB (PythonçŽ¯å¢ƒ + é¡¹ç›®ä»£ç )"
echo "   æ•°æ®ç›˜: ~40-185GB (æ¨¡åž‹ + æ•°æ® + æ–‡æ¡£)"
echo ""
echo "ðŸ”§ æŽ¥ä¸‹æ¥éœ€è¦é…ç½®ï¼š"
echo "   1. é…ç½®åƒé—®Agentçš„Function Call"
echo "   2. å¯åŠ¨çŸ¥è¯†åº“æœåŠ¡"
echo "   3. æµ‹è¯•Function CallæŽ¥å£"
echo "   4. é…ç½®7B LoRAå¾®è°ƒ"
echo ""
echo "ðŸ“– è¯¦ç»†é…ç½®è¯´æ˜Žè¯·æŸ¥çœ‹ï¼š"
echo "   - qwen_agent_config.md (åƒé—®Agenté…ç½®)"
echo "   - storage_usage.md (å­˜å‚¨ç©ºé—´ä½¿ç”¨è¯´æ˜Ž)"
echo "   - ä¼ä¸šçŸ¥è¯†åº“æ­å»ºæ–¹æ¡ˆ.md (å®Œæ•´é…ç½®æŒ‡å—)"
echo ""
echo "âš ï¸  é‡è¦æé†’ï¼š"
echo "   - è¯·å…ˆé…ç½®.envæ–‡ä»¶ä¸­çš„APIå¯†é’¥"
echo "   - ç¡®ä¿Milvuså‘é‡æ•°æ®åº“å·²å¯åŠ¨"
echo "   - æ ¹æ®éœ€è¦è°ƒæ•´Function Callé…ç½®"
echo "   - æ¨¡åž‹æ–‡ä»¶å·²è‡ªåŠ¨é…ç½®åˆ°æ•°æ®ç›˜"
echo ""
echo "ðŸš€ çŽ°åœ¨å¯ä»¥å¯åŠ¨æœåŠ¡äº†ï¼"
echo "   cd ~/enterprise_kb_service && ./start_service.sh"

一、AutoDL 租机 + 端口开放
选「RTX 4090 24 GB」镜像，租好后记下 公网 IP 与 SSH 端口（AutoDL 会给出）。
在 AutoDL 控制台 →「端口映射」→ 新增 3000 端口（Dify 默认 Web 端口）。
用 SSH 登录服务器（Windows 可用 Xshell / MobaXterm）。
二、Ubuntu 纯命令行完整部署步骤（可复制粘贴）
# 0. 更新系统
sudo apt update && sudo apt upgrade -y

# 1. 安装 Docker + Docker Compose
sudo apt install -y curl git
curl -fsSL https://get.docker.com | sudo bash
sudo usermod -aG docker $USER
newgrp docker          # 使 docker 免 sudo
docker --version       # 验证

# 2. 拉取并进入 Dify
git clone https://github.com/langgenius/dify.git
cd dify/docker

# 3. 生成并编辑环境变量
cp .env.example .env
# 若仅做 Demo，可先不改动（保持 3000 端口）
# 如需改端口：nano .env，把 EXPOSE_NGINX_PORT=80 改成 8080 等

# 4. 一键启动（后台）
docker compose up -d

# 5. 查看容器状态
docker compose ps



二、Dify 与 7B-LoRA 能否一起跑？
可以，三种主流方案任选其一：
Ollama + LoRA（最简单）
先在服务器 ollama run deepseek-r1:7b 启动 7B 模型；
Dify 的「模型提供商」里选 Ollama，填写
复制
API Base URL = http://<内网IP>:11434
Model Name   = deepseek-r1:7b
即可在 Dify 前端直接调用 7B-LoRA 权重


把“缺失的三件事”补进刚才的 30 分钟清单，形成「0→1 Demo」完整脚本。你只需在 AutoDL 的 Ubuntu 服务器上依次执行即可。

────────────────  
完整 60 分钟 Demo 脚本（含 RAG + Embedding + LoRA 微调）

前置准备（2 分钟）  
```bash
# 确认已按上一条完成 Docker & Dify 启动
docker compose ps | grep dify
```

本地向量库 & Embedding 模型（5 分钟）
```bash
# 启动 Milvus-Lite（单节点，足够演示）
docker run -d --name milvus \
  -p 19530:19530 -p 9091:9091 \
  milvusdb/milvus:v2.3.8-lite

# 启动 bge-large-zh 向量服务（CPU/4090 均可）
docker run -d --name bge \
  -p 6006:6006 \
  -e MODEL_NAME=BAAI/bge-large-zh \
  registry.cn-hangzhou.aliyuncs.com/fastgpt/bge-large-zh:latest
```

LoRA 微调 7B 模型（20 分钟）  
```bash
# 1) 拉取 7B 基础模型 + LoRA 脚本
git clone https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -r requirements.txt

# 2) 把你的 100 份文档 + 1000 条 QA 做成 JSONL
# 格式：{"instruction":"...","input":"...","output":"..."}
nano data/my_corp.jsonl

# 3) 一键微调（QLoRA 4-bit，单卡 4090 足够）
python src/train_bash.py \
  --stage sft \
  --model_name_or_path deepseek-ai/DeepSeek-R1-Distill-Qwen-7B \
  --dataset my_corp \
  --template qwen \
  --finetuning_type lora \
  --output_dir ./lora_ckpt \
  --per_device_train_batch_size 4 \
  --gradient_accumulation_steps 4 \
  --num_train_epochs 1 \
  --quantization_bit 4 \
  --learning_rate 3e-4 \
  --fp16

# 4) 微调完得到 lora_ckpt 文件夹
```

把 LoRA 权重挂到推理服务（5 分钟）
```bash
# 使用 vLLM 启动带 LoRA 的 7B
docker run -d --name vllm_lora \
  -p 8000:8000 \
  -v $(pwd)/lora_ckpt:/lora \
  vllm/vllm-openai:latest \
  --model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B \
  --enable-lora \
  --lora-modules my_lora=/lora

# 测试
curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model":"my_lora","messages":[{"role":"user","content":"ESS 培训每月几次？"}]}'
```

把向量库 + LoRA 接入 Dify（5 分钟）
- 浏览器进入 `http://<公网IP>:3000`  
- 设置 → 模型提供商 → **向量库** 选 Milvus，填  
  ```
  host: 127.0.0.1
  port: 19530
  ```  
- **LLM** 选 **OpenAI-API-Compatible**，填  
  ```
  API Base: http://localhost:8000/v1
  Model Name: my_lora
  ```

上传文档 & 向量化（5 分钟）
- Dify 知识库 → 新建 → 上传 100 份文档 → 选择 **bge-large-zh** 作为 Embedding → 自动切块 → 索引完成。

验证（3 分钟）
- 在 Dify 聊天界面提问：“ESS 培训每月几次？”  
- 应返回带引用、带档案号的答案。

────────────────  
一键脚本放到 `setup_demo.sh` 即可 60 分钟跑通：
#!/bin/bash
# 企业知识库 72h Demo 一键部署脚本（最终版 2025-08-14）
# 适用：AutoDL Ubuntu 22.04 + RTX 4090 24 GB
set -e

echo "====== 0) 系统基础 ======"
sudo apt update -y
sudo apt install -y curl git build-essential

# 安装 Docker & Compose
curl -fsSL https://get.docker.com | sudo bash
sudo usermod -aG docker $USER && newgrp docker

# ====== 1) 向量库 Milvus ======
docker run -d --name milvus \
  -p 19530:19530 -p 9091:9091 \
  milvusdb/milvus:v2.3.8-lite

# ====== 2) 文本 Embedding 服务 ======
docker run -d --name bge \
  -p 6006:6006 \
  -e MODEL_NAME=BAAI/bge-large-zh \
  registry.cn-hangzhou.aliyuncs.com/fastgpt/bge-large-zh:latest

# ====== 3) 视频/图纸多模态服务 ======
docker run -d --name minicpm_video \
  -p 9000:9000 \
  -e MODEL_NAME=openbmb/MiniCPM-V-2_6 \
  registry.cn-hangzhou.aliyuncs.com/minicpm/minicpm-v2_6:latest

# ====== 4) LoRA 微调 & vLLM 推理 ======
git clone https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# 4-1 准备示例数据
cat > data/my_corp.jsonl <<EOF
{"instruction":"ESS 培训每月几次？","input":"","output":"每月 3 次，详见《ESS 培训签到表》第 3 页"}
{"instruction":"打印机出现数据库连接失败怎么办？","input":"","output":"先检查 MSSQLSERVER 服务是否启动，再确认 1433 端口是否放行，详细步骤见《部署手册》第 12 页"}
EOF

# 4-2 QLoRA 微调（单卡 4090 4-bit，约 30 分钟）
python src/train_bash.py \
  --stage sft \
  --model_name_or_path deepseek-ai/DeepSeek-R1-Distill-Qwen-7B \
  --dataset my_corp \
  --template qwen \
  --finetuning_type lora \
  --output_dir ./lora_ckpt \
  --per_device_train_batch_size 4 \
  --gradient_accumulation_steps 4 \
  --num_train_epochs 1 \
  --quantization_bit 4 \
  --learning_rate 3e-4 \
  --fp16

# 4-3 启动带 LoRA 的 vLLM
docker run -d --name vllm_lora \
  -p 8000:8000 \
  -v $(pwd)/lora_ckpt:/lora \
  vllm/vllm-openai:latest \
  --model deepseek-ai/DeepSeek-R1-Distill-Qwen-7B \
  --enable-lora \
  --lora-modules my_lora=/lora

# ====== 5) Dify 本体 ======
cd ~
git clone https://github.com/langgenius/dify.git
cd dify/docker
cp .env.example .env
# 如需改端口：nano .env → EXPOSE_NGINX_PORT=3000
docker compose up -d

# ====== 6) 一键验证 ======
echo "====== 全部服务已启动 ======"
echo "Dify 面板:  http://<公网IP>:3000"
echo "LoRA API:   http://<公网IP>:8000/v1"
echo "视频 API:   http://<公网IP>:9000/docs"
echo "向量库:     http://<公网IP>:19530"
echo "====== 接下来 ======"
echo "1 浏览器打开 Dify → 新建知识库 → 上传 100 份文档 → 选 bge-large-zh"
echo "2 新建 Chatbot → 选 LoRA 模型 → 开始问答"  








```
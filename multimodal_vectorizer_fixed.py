#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼ä¸šçŸ¥è¯†åº“å¤šæ¨¡æ€å‘é‡åŒ–ç³»ç»Ÿ (ä¿®å¤ç‰ˆæœ¬)
æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘çš„ç»Ÿä¸€å‘é‡åŒ–å’Œæ£€ç´¢
"""

import os
import sys
import logging
import json
import pickle
from pathlib import Path
from typing import List, Dict, Any, Optional, Union
import numpy as np

# å›¾åƒå¤„ç†
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go

# éŸ³é¢‘å¤„ç†
import librosa
import soundfile as sf

# OCRå’Œå›¾è¡¨ç†è§£
import easyocr
from transformers import pipeline

# æ–‡æœ¬å¤„ç†å’Œå‘é‡åŒ–
from sentence_transformers import SentenceTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
import faiss

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MultimodalVectorizer:
    """å¤šæ¨¡æ€å‘é‡åŒ–å™¨ - æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘çš„ç»Ÿä¸€å¤„ç†"""
    
    def __init__(self,
                 text_model: str = "BAAI/bge-large-zh-v1.5",
                 image_model: str = "microsoft/DialoGPT-medium",
                 device: str = "auto"):
        """
        åˆå§‹åŒ–å¤šæ¨¡æ€å‘é‡åŒ–å™¨
        
        Args:
            text_model: æ–‡æœ¬åµŒå…¥æ¨¡å‹åç§°
            image_model: å›¾åƒç†è§£æ¨¡å‹åç§°
            device: è®¡ç®—è®¾å¤‡ ('auto', 'cuda', 'cpu')
        """
        try:
            import torch
            self.device = device if device != "auto" else ("cuda" if torch.cuda.is_available() else "cpu")
        except ImportError:
            self.device = "cpu"
        self.text_model = text_model
        self.image_model = image_model
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.text_embeddings = None
        self.text_splitter = None
        self.ocr_reader = None
        self.chart_analyzer = None
        self.vector_db = None
        
        logger.info(f"åˆå§‹åŒ–å¤šæ¨¡æ€å‘é‡åŒ–å™¨ï¼Œè®¾å¤‡: {self.device}")
        self._initialize_processors()
    
    def _initialize_processors(self):
        """åˆå§‹åŒ–æ‰€æœ‰å¤„ç†å™¨"""
        try:
            # 1. æ–‡æœ¬åµŒå…¥æ¨¡å‹
            logger.info("åˆå§‹åŒ–æ–‡æœ¬åµŒå…¥æ¨¡å‹...")
            self.text_embeddings = SentenceTransformer(self.text_model, device=self.device)
            
            # 2. æ–‡æœ¬åˆ†å‰²å™¨
            self.text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50,
                length_function=len,
                separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?"]
            )
            
            # 3. OCRæ–‡æœ¬è¯†åˆ«
            logger.info("åˆå§‹åŒ–OCRå¤„ç†å™¨...")
            try:
                import torch
                gpu_available = torch.cuda.is_available()
            except ImportError:
                gpu_available = False
            self.ocr_reader = easyocr.Reader(['ch_sim', 'en'], gpu=gpu_available)
            
            # 4. å›¾è¡¨ç†è§£æ¨¡å‹
            logger.info("åˆå§‹åŒ–å›¾è¡¨ç†è§£æ¨¡å‹...")
            self.chart_analyzer = pipeline(
                "image-to-text", 
                model=self.image_model, 
                device=0 if self.device == "cuda" else -1
            )
            
            logger.info("âœ… æ‰€æœ‰æ¨¡æ€å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å¤„ç†å™¨å¤±è´¥: {e}")
            raise
    
    def _fix_pil_compatibility(self, image):
        """ä¿®å¤PILç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜"""
        try:
            # å°è¯•ä½¿ç”¨æ–°çš„resamplingæ–¹æ³•
            if hasattr(Image, 'Resampling'):
                return image.resize(image.size, Image.Resampling.LANCZOS)
            else:
                # å›é€€åˆ°æ—§ç‰ˆæœ¬æ–¹æ³•
                return image.resize(image.size, Image.ANTIALIAS)
        except AttributeError:
            # å¦‚æœéƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤æ–¹æ³•
            return image.resize(image.size)
    
    def process_image(self, image_path: str, metadata: Dict[str, Any] = None) -> List[Document]:
        """
        å¤„ç†å›¾åƒæ–‡ä»¶ï¼šOCR + å›¾è¡¨ç†è§£ + å›¾åƒç‰¹å¾
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            metadata: å…ƒæ•°æ®
            
        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        documents = []
        
        try:
            # è¯»å–å›¾åƒ
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            
            # è½¬æ¢ä¸ºRGB
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            height, width, channels = image.shape
            
            # 1. OCRæ–‡æœ¬æå–
            logger.info(f"æ‰§è¡ŒOCRè¯†åˆ«: {image_path}")
            ocr_results = self.ocr_reader.readtext(image_path)
            
            if ocr_results:
                ocr_text = " ".join([result[1] for result in ocr_results])
                ocr_doc = Document(
                    page_content=f"å›¾åƒä¸­çš„æ–‡å­—å†…å®¹: {ocr_text}",
                    metadata={
                        "source": image_path,
                        "type": "image_ocr",
                        "ocr_text": ocr_text,
                        "ocr_confidence": [result[2] for result in ocr_results],
                        **(metadata or {})
                    }
                )
                documents.append(ocr_doc)
                logger.info(f"OCRè¯†åˆ«åˆ° {len(ocr_results)} ä¸ªæ–‡æœ¬åŒºåŸŸ")
            
            # 2. å›¾è¡¨ç†è§£ï¼ˆå°è¯•ï¼‰
            try:
                logger.info("å°è¯•å›¾è¡¨ç†è§£...")
                pil_image = Image.open(image_path)
                # ä¿®å¤PILå…¼å®¹æ€§é—®é¢˜
                pil_image = self._fix_pil_compatibility(pil_image)
                
                chart_description = self.chart_analyzer(pil_image)[0]['generated_text']
                chart_doc = Document(
                    page_content=f"å›¾è¡¨å†…å®¹æè¿°: {chart_description}",
                    metadata={
                        "source": image_path,
                        "type": "image_chart",
                        "chart_description": chart_description,
                        **(metadata or {})
                    }
                )
                documents.append(chart_doc)
                logger.info("å›¾è¡¨ç†è§£å®Œæˆ")
                
            except Exception as e:
                logger.warning(f"å›¾è¡¨ç†è§£å¤±è´¥: {e}")
            
            # 3. å›¾åƒç‰¹å¾æè¿°
            # è®¡ç®—åŸºæœ¬å›¾åƒç‰¹å¾
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            brightness = np.mean(gray)
            contrast = np.std(gray)
            
            # æ£€æµ‹è¾¹ç¼˜
            edges = cv2.Canny(gray, 50, 150)
            edge_density = np.sum(edges > 0) / (height * width)
            
            image_features = {
                "å°ºå¯¸": f"{width}x{height}",
                "é€šé“æ•°": channels,
                "äº®åº¦": f"{brightness:.1f}",
                "å¯¹æ¯”åº¦": f"{contrast:.1f}",
                "è¾¹ç¼˜å¯†åº¦": f"{edge_density:.3f}"
            }
            
            feature_doc = Document(
                page_content=f"å›¾åƒç‰¹å¾: {json.dumps(image_features, ensure_ascii=False)}",
                metadata={
                    "source": image_path,
                    "type": "image_features",
                    "image_features": image_features,
                    **(metadata or {})
                }
            )
            documents.append(feature_doc)
            
            logger.info(f"å›¾åƒå¤„ç†å®Œæˆ: {len(documents)} ä¸ªæ–‡æ¡£")
            
        except Exception as e:
            logger.error(f"å›¾åƒå¤„ç†å¤±è´¥ {image_path}: {e}")
            # åˆ›å»ºé”™è¯¯æ–‡æ¡£
            error_doc = Document(
                page_content=f"å›¾åƒå¤„ç†å¤±è´¥: {str(e)}",
                metadata={
                    "source": image_path,
                    "type": "image_error",
                    "error": str(e),
                    **(metadata or {})
                }
            )
            documents.append(error_doc)
        
        return documents
    
    def process_video(self, video_path: str, metadata: Dict[str, Any] = None) -> List[Document]:
        """
        å¤„ç†è§†é¢‘æ–‡ä»¶ï¼šå…³é”®å¸§æå– + éŸ³é¢‘åˆ†æ
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            metadata: å…ƒæ•°æ®
            
        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        documents = []
        
        try:
            # è¯»å–è§†é¢‘
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            
            # è·å–è§†é¢‘ä¿¡æ¯
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = frame_count / fps if fps > 0 else 0
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            
            # 1. å…³é”®å¸§æå–
            logger.info(f"æå–è§†é¢‘å…³é”®å¸§: {video_path}")
            key_frames = self._extract_key_frames(cap, frame_count)
            
            frame_doc = Document(
                page_content=f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps:.1f}fps, {duration:.1f}ç§’, {frame_count}å¸§, æå–{len(key_frames)}ä¸ªå…³é”®å¸§",
                metadata={
                    "source": video_path,
                    "type": "video_frames",
                    "video_info": {
                        "width": width, "height": height, "fps": fps,
                        "frame_count": frame_count, "duration": duration,
                        "key_frames_count": len(key_frames)
                    },
                    **(metadata or {})
                }
            )
            documents.append(frame_doc)
            
            # 2. éŸ³é¢‘åˆ†æï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            try:
                audio_features = self._analyze_video_audio(video_path)
                if audio_features:
                    audio_doc = Document(
                        page_content=f"éŸ³é¢‘ç‰¹å¾: èŠ‚æ‹={audio_features.get('tempo', 'N/A')}BPM, é¢‘è°±è´¨å¿ƒ={audio_features.get('spectral_centroid', 'N/A')}Hz",
                        metadata={
                            "source": video_path,
                            "type": "video_audio",
                            "audio_features": audio_features,
                            **(metadata or {})
                        }
                    )
                    documents.append(audio_doc)
            except Exception as e:
                logger.warning(f"éŸ³é¢‘åˆ†æå¤±è´¥: {e}")
            
            cap.release()
            logger.info(f"è§†é¢‘å¤„ç†å®Œæˆ: {len(documents)} ä¸ªæ–‡æ¡£")
            
        except Exception as e:
            logger.error(f"è§†é¢‘å¤„ç†å¤±è´¥ {video_path}: {e}")
            error_doc = Document(
                page_content=f"è§†é¢‘å¤„ç†å¤±è´¥: {str(e)}",
                metadata={
                    "source": video_path,
                    "type": "video_error",
                    "error": str(e),
                    **(metadata or {})
                }
            )
            documents.append(error_doc)
        
        return documents
    
    def _extract_key_frames(self, cap, frame_count: int, max_frames: int = 10) -> List[np.ndarray]:
        """æå–å…³é”®å¸§"""
        key_frames = []
        if frame_count <= max_frames:
            # å¦‚æœå¸§æ•°ä¸å¤šï¼Œå…¨éƒ¨æå–
            for i in range(frame_count):
                cap.set(cv2.CAP_PROP_POS_FRAMES, i)
                ret, frame = cap.read()
                if ret:
                    key_frames.append(frame)
        else:
            # å‡åŒ€é‡‡æ ·
            step = frame_count // max_frames
            for i in range(0, frame_count, step):
                cap.set(cv2.CAP_PROP_POS_FRAMES, i)
                ret, frame = cap.read()
                if ret and len(key_frames) < max_frames:
                    key_frames.append(frame)
        
        return key_frames
    
    def _analyze_video_audio(self, video_path: str) -> Dict[str, Any]:
        """åˆ†æè§†é¢‘ä¸­çš„éŸ³é¢‘"""
        try:
            # ä½¿ç”¨librosaåˆ†æéŸ³é¢‘
            y, sr = librosa.load(video_path, sr=None)
            
            # æå–éŸ³é¢‘ç‰¹å¾
            tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            
            return {
                "tempo": float(tempo),
                "spectral_centroid": float(np.mean(spectral_centroids)),
                "mfcc_mean": float(np.mean(mfccs)),
                "duration": float(len(y) / sr)
            }
        except Exception as e:
            logger.warning(f"éŸ³é¢‘åˆ†æå¤±è´¥: {e}")
            return {}
    
    def process_audio(self, audio_path: str, metadata: Dict[str, Any] = None) -> List[Document]:
        """
        å¤„ç†éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            metadata: å…ƒæ•°æ®
            
        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        try:
            # åŠ è½½éŸ³é¢‘
            y, sr = librosa.load(audio_path, sr=None)
            duration = len(y) / sr
            
            # æå–éŸ³é¢‘ç‰¹å¾
            tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            
            # è®¡ç®—ç»Ÿè®¡ç‰¹å¾
            features = {
                "æ—¶é•¿": f"{duration:.2f}ç§’",
                "é‡‡æ ·ç‡": f"{sr}Hz",
                "èŠ‚æ‹": f"{tempo:.1f}BPM",
                "é¢‘è°±è´¨å¿ƒ": f"{np.mean(spectral_centroids):.1f}Hz",
                "MFCCå‡å€¼": f"{np.mean(mfccs):.3f}",
                "éŸ³é‡": f"{np.mean(np.abs(y)):.3f}"
            }
            
            audio_doc = Document(
                page_content=f"éŸ³é¢‘ç‰¹å¾: {json.dumps(features, ensure_ascii=False)}",
                metadata={
                    "source": audio_path,
                    "type": "audio",
                    "audio_features": features,
                    **(metadata or {})
                }
            )
            
            logger.info(f"éŸ³é¢‘å¤„ç†å®Œæˆ: {audio_path}")
            return [audio_doc]
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘å¤„ç†å¤±è´¥ {audio_path}: {e}")
            error_doc = Document(
                page_content=f"éŸ³é¢‘å¤„ç†å¤±è´¥: {str(e)}",
                metadata={
                    "source": audio_path,
                    "type": "audio_error",
                    "error": str(e),
                    **(metadata or {})
                }
            )
            return [error_doc]
    
    def process_file(self, file_path: str, metadata: Dict[str, Any] = None) -> List[Document]:
        """
        æ ¹æ®æ–‡ä»¶ç±»å‹è‡ªåŠ¨åˆ†å‘åˆ°ç›¸åº”çš„å¤„ç†å™¨
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            metadata: å…ƒæ•°æ®
            
        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        file_path = str(file_path)
        file_ext = Path(file_path).suffix.lower()
        
        logger.info(f"å¤„ç†æ–‡ä»¶: {file_path} (ç±»å‹: {file_ext})")
        
        if file_ext in ['.txt', '.md', '.json', '.csv', '.pdf']:
            # æ–‡æœ¬æ–‡ä»¶
            return self.process_text_file(file_path, metadata)
        elif file_ext in ['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff']:
            # å›¾åƒæ–‡ä»¶
            return self.process_image(file_path, metadata)
        elif file_ext in ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv']:
            # è§†é¢‘æ–‡ä»¶
            return self.process_video(file_path, metadata)
        elif file_ext in ['.mp3', '.wav', '.flac', '.aac', '.ogg']:
            # éŸ³é¢‘æ–‡ä»¶
            return self.process_audio(file_path, metadata)
        else:
            logger.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}")
            return []
    
    def process_text_file(self, file_path: str, metadata: Dict[str, Any] = None) -> List[Document]:
        """å¤„ç†æ–‡æœ¬æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ–‡æœ¬åˆ†å‰²
            chunks = self.text_splitter.split_text(content)
            
            documents = []
            for i, chunk in enumerate(chunks):
                doc = Document(
                    page_content=chunk,
                    metadata={
                        "source": file_path,
                        "type": "text",
                        "chunk_id": i,
                        "total_chunks": len(chunks),
                        **(metadata or {})
                    }
                )
                documents.append(doc)
            
            logger.info(f"æ–‡æœ¬æ–‡ä»¶å¤„ç†å®Œæˆ: {len(documents)} ä¸ªæ–‡æ¡£å—")
            return documents
            
        except Exception as e:
            logger.error(f"æ–‡æœ¬æ–‡ä»¶å¤„ç†å¤±è´¥ {file_path}: {e}")
            return []
    
    def process_directory(self, directory_path: str, metadata: Dict[str, Any] = None) -> List[Document]:
        """
        é€’å½’å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        
        Args:
            directory_path: ç›®å½•è·¯å¾„
            metadata: å…ƒæ•°æ®
            
        Returns:
            æ‰€æœ‰æ–‡æ¡£çš„åˆ—è¡¨
        """
        all_documents = []
        directory_path = Path(directory_path)
        
        if not directory_path.exists():
            logger.error(f"ç›®å½•ä¸å­˜åœ¨: {directory_path}")
            return all_documents
        
        # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        supported_extensions = {
            '.txt', '.md', '.json', '.csv', '.pdf',  # æ–‡æœ¬
            '.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff',  # å›¾åƒ
            '.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv',  # è§†é¢‘
            '.mp3', '.wav', '.flac', '.aac', '.ogg'  # éŸ³é¢‘
        }
        
        for file_path in directory_path.rglob('*'):
            if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
                try:
                    file_metadata = {
                        "file_name": file_path.name,
                        "file_size": file_path.stat().st_size,
                        "file_path": str(file_path),
                        **(metadata or {})
                    }
                    
                    documents = self.process_file(str(file_path), file_metadata)
                    all_documents.extend(documents)
                    
                except Exception as e:
                    logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        logger.info(f"ç›®å½•å¤„ç†å®Œæˆ: {len(all_documents)} ä¸ªæ–‡æ¡£")
        return all_documents
    
    def build_vector_database(self, documents: List[Document], save_path: str = "multimodal_vector_db") -> None:
        """
        æ„å»ºå‘é‡æ•°æ®åº“
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            save_path: ä¿å­˜è·¯å¾„
        """
        if not documents:
            logger.warning("æ²¡æœ‰æ–‡æ¡£éœ€è¦å‘é‡åŒ–")
            return
        
        try:
            logger.info(f"å¼€å§‹æ„å»ºå‘é‡æ•°æ®åº“ï¼Œæ–‡æ¡£æ•°é‡: {len(documents)}")
            
            # æå–æ–‡æœ¬å†…å®¹
            texts = [doc.page_content for doc in documents]
            metadatas = [doc.metadata for doc in documents]
            
            # ä½¿ç”¨sentence-transformersè¿›è¡Œæ–‡æœ¬åµŒå…¥
            embeddings = self.text_embeddings.encode(texts, show_progress_bar=True)
            
            # åˆ›å»ºFAISSç´¢å¼•
            dimension = embeddings.shape[1]
            index = faiss.IndexFlatIP(dimension)
            
            # å½’ä¸€åŒ–å‘é‡
            faiss.normalize_L2(embeddings)
            
            # æ·»åŠ å‘é‡åˆ°ç´¢å¼•
            index.add(embeddings.astype('float32'))
            
            # ä¿å­˜ç´¢å¼•å’Œå…ƒæ•°æ®
            os.makedirs(save_path, exist_ok=True)
            
            # ä¿å­˜FAISSç´¢å¼•
            faiss.write_index(index, os.path.join(save_path, "faiss.index"))
            
            # ä¿å­˜å…ƒæ•°æ®
            with open(os.path.join(save_path, "metadata.pkl"), 'wb') as f:
                pickle.dump(metadatas, f)
            
            # ä¿å­˜æ–‡æ¡£
            with open(os.path.join(save_path, "documents.pkl"), 'wb') as f:
                pickle.dump(documents, f)
            
            # ä¿å­˜é…ç½®ä¿¡æ¯
            config = {
                "model_name": self.text_model,
                "embedding_dimension": dimension,
                "document_count": len(documents),
                "document_types": list(set(doc.metadata.get("type", "unknown") for doc in documents))
            }
            
            with open(os.path.join(save_path, "config.json"), 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            
            self.vector_db = {
                "index": index,
                "metadatas": metadatas,
                "documents": documents,
                "config": config
            }
            
            logger.info(f"âœ… å‘é‡æ•°æ®åº“æ„å»ºå®Œæˆï¼ä¿å­˜è·¯å¾„: {save_path}")
            logger.info(f"ç´¢å¼•ä¿¡æ¯: {dimension}ç»´, {len(documents)}ä¸ªæ–‡æ¡£")
            
        except Exception as e:
            logger.error(f"æ„å»ºå‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            raise
    
    def search_similar(self, query: str, top_k: int = 5, filter_type: str = None) -> List[Dict[str, Any]]:
        """
        æœç´¢ç›¸ä¼¼æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            filter_type: è¿‡æ»¤æ–‡æ¡£ç±»å‹
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self.vector_db:
            logger.error("å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")
            return []
        
        try:
            # æŸ¥è¯¢å‘é‡åŒ–
            query_embedding = self.text_embeddings.encode([query])
            faiss.normalize_L2(query_embedding)
            
            # æœç´¢
            scores, indices = self.vector_db["index"].search(
                query_embedding.astype('float32'), 
                top_k
            )
            
            results = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if idx < len(self.vector_db["documents"]):
                    doc = self.vector_db["documents"][idx]
                    metadata = self.vector_db["metadatas"][idx]
                    
                    # ç±»å‹è¿‡æ»¤
                    if filter_type and metadata.get("type") != filter_type:
                        continue
                    
                    result = {
                        "rank": i + 1,
                        "score": float(score),
                        "content": doc.page_content,
                        "metadata": metadata
                    }
                    results.append(result)
            
            logger.info(f"æœç´¢å®Œæˆ: æŸ¥è¯¢'{query}'ï¼Œè¿”å›{len(results)}ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_database_info(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“ä¿¡æ¯"""
        if not self.vector_db:
            return {"status": "æœªåˆå§‹åŒ–"}
        
        return {
            "status": "å·²åˆå§‹åŒ–",
            "config": self.vector_db["config"],
            "document_count": len(self.vector_db["documents"]),
            "index_size": self.vector_db["index"].ntotal
        }

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå¤šæ¨¡æ€å‘é‡åŒ–ç³»ç»Ÿ"""
    print("ğŸš€ ä¼ä¸šçŸ¥è¯†åº“å¤šæ¨¡æ€å‘é‡åŒ–ç³»ç»Ÿ")
    print("=" * 60)
    
    # åˆå§‹åŒ–å‘é‡åŒ–å™¨
    vectorizer = MultimodalVectorizer()
    
    # ç¤ºä¾‹æ•°æ®è·¯å¾„
    sample_docs = "sample_docs"
    
    if not os.path.exists(sample_docs):
        print(f"âŒ ç¤ºä¾‹æ•°æ®ç›®å½•ä¸å­˜åœ¨: {sample_docs}")
        print("è¯·å…ˆè¿è¡Œ test_multimodal_system.py åˆ›å»ºç¤ºä¾‹æ•°æ®")
        return
    
    # å¤„ç†ä¸åŒç±»å‹çš„æ–‡æ¡£
    print("\nğŸ“ å¼€å§‹å¤„ç†å¤šæ¨¡æ€æ–‡æ¡£...")
    
    # 1. å¤„ç†æ–‡æœ¬æ–‡æ¡£
    text_docs = vectorizer.process_directory(os.path.join(sample_docs, "texts"))
    
    # 2. å¤„ç†å›¾åƒæ–‡æ¡£
    image_docs = vectorizer.process_directory(os.path.join(sample_docs, "images"))
    
    # 3. å¤„ç†è§†é¢‘æ–‡æ¡£
    video_docs = vectorizer.process_directory(os.path.join(sample_docs, "videos"))
    
    # 4. å¤„ç†éŸ³é¢‘æ–‡æ¡£
    audio_docs = vectorizer.process_directory(os.path.join(sample_docs, "audios"))
    
    # åˆå¹¶æ‰€æœ‰æ–‡æ¡£
    all_documents = text_docs + image_docs + video_docs + audio_docs
    
    print(f"\nğŸ“Š æ–‡æ¡£å¤„ç†ç»Ÿè®¡:")
    print(f"æ–‡æœ¬æ–‡æ¡£: {len(text_docs)} ä¸ª")
    print(f"å›¾åƒæ–‡æ¡£: {len(image_docs)} ä¸ª")
    print(f"è§†é¢‘æ–‡æ¡£: {len(video_docs)} ä¸ª")
    print(f"éŸ³é¢‘æ–‡æ¡£: {len(audio_docs)} ä¸ª")
    print(f"æ€»è®¡: {len(all_documents)} ä¸ªæ–‡æ¡£")
    
    if all_documents:
        # æ„å»ºå‘é‡æ•°æ®åº“
        print("\nğŸ”¨ æ„å»ºå‘é‡æ•°æ®åº“...")
        vectorizer.build_vector_database(all_documents, "multimodal_vector_db")
        
        # æµ‹è¯•æœç´¢åŠŸèƒ½
        print("\nğŸ” æµ‹è¯•æœç´¢åŠŸèƒ½...")
        test_queries = [
            "å•†ä¸šåˆåŒ",
            "è´¢åŠ¡æŠ¥è¡¨",
            "äº§å“å›¾ç‰‡",
            "ä¼šè®®è§†é¢‘",
            "éŸ³é¢‘æ–‡ä»¶"
        ]
        
        for query in test_queries:
            print(f"\næŸ¥è¯¢: '{query}'")
            results = vectorizer.search_similar(query, top_k=3)
            
            for result in results:
                print(f"  [{result['rank']}] ç›¸ä¼¼åº¦: {result['score']:.3f}")
                print(f"      ç±»å‹: {result['metadata'].get('type', 'unknown')}")
                print(f"      å†…å®¹: {result['content'][:100]}...")
        
        # æ˜¾ç¤ºæ•°æ®åº“ä¿¡æ¯
        print("\nğŸ“Š æ•°æ®åº“ä¿¡æ¯:")
        db_info = vectorizer.get_database_info()
        for key, value in db_info.items():
            print(f"  {key}: {value}")
    
    print("\nğŸ‰ å¤šæ¨¡æ€å‘é‡åŒ–ç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼")

if __name__ == "__main__":
    main()

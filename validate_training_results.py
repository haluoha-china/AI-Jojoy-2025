#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®­ç»ƒåéªŒè¯è„šæœ¬ - ä½¿ç”¨åˆ†å±‚éªŒè¯æµ‹è¯•é›†éªŒè¯å…¨é‡æ•°æ®è®­ç»ƒæ•ˆæœ
"""

import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Any

class TrainingValidator:
    """è®­ç»ƒç»“æœéªŒè¯å™¨"""
    
    def __init__(self, test_set_path: str, model_checkpoint: str):
        self.test_set_path = test_set_path
        self.model_checkpoint = model_checkpoint
        self.test_cases = []
        self.validation_results = []
        
    def load_test_set(self):
        """åŠ è½½åˆ†å±‚éªŒè¯æµ‹è¯•é›†"""
        try:
            with open(self.test_set_path, 'r', encoding='utf-8') as f:
                test_data = json.load(f)
            
            self.test_cases = test_data.get('test_cases', [])
            print(f"âœ… æˆåŠŸåŠ è½½æµ‹è¯•é›†ï¼ŒåŒ…å« {len(self.test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
            
            # æ˜¾ç¤ºæµ‹è¯•é›†ç»Ÿè®¡
            layer_stats = {}
            for test_case in self.test_cases:
                layer = test_case.get('layer', 'æœªçŸ¥')
                layer_stats[layer] = layer_stats.get(layer, 0) + 1
            
            print("\nğŸ“Š æµ‹è¯•é›†åˆ†å±‚ç»Ÿè®¡:")
            for layer, count in layer_stats.items():
                print(f"  {layer}: {count} ä¸ªæµ‹è¯•ç”¨ä¾‹")
                
        except Exception as e:
            print(f"âŒ åŠ è½½æµ‹è¯•é›†å¤±è´¥: {e}")
            raise
    
    def validate_basic_knowledge(self) -> Dict[str, Any]:
        """éªŒè¯ç¬¬ä¸€å±‚ï¼šåŸºç¡€çŸ¥è¯†æŒæ¡åº¦"""
        print("\nğŸ” éªŒè¯ç¬¬ä¸€å±‚ï¼šåŸºç¡€çŸ¥è¯†æŒæ¡åº¦æµ‹è¯•")
        
        basic_tests = [t for t in self.test_cases if t.get('layer') == 'åŸºç¡€çŸ¥è¯†æŒæ¡åº¦æµ‹è¯•']
        print(f"  æµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(basic_tests)}")
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨æ¨¡å‹è¿›è¡Œå®é™…æµ‹è¯•
        # ç›®å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º
        results = {
            'layer': 'åŸºç¡€çŸ¥è¯†æŒæ¡åº¦æµ‹è¯•',
            'total_tests': len(basic_tests),
            'passed_tests': 0,
            'failed_tests': 0,
            'pass_rate': 0.0,
            'sample_results': []
        }
        
        # æ¨¡æ‹Ÿæµ‹è¯•ç»“æœ
        for i, test_case in enumerate(basic_tests[:5]):  # åªæµ‹è¯•å‰5ä¸ªä½œä¸ºç¤ºä¾‹
            test_result = {
                'test_id': test_case.get('test_id'),
                'instruction': test_case.get('instruction'),
                'expected': test_case.get('expected_answer'),
                'status': 'æ¨¡æ‹Ÿæµ‹è¯•'  # å®é™…ä½¿ç”¨æ—¶è¿™é‡Œåº”è¯¥æ˜¯çœŸå®çš„æ¨¡å‹å›ç­”
            }
            results['sample_results'].append(test_result)
        
        return results
    
    def validate_confusion_boundary(self) -> Dict[str, Any]:
        """éªŒè¯ç¬¬äºŒå±‚ï¼šæ··æ·†å’Œè¾¹ç•Œæµ‹è¯•"""
        print("\nğŸ” éªŒè¯ç¬¬äºŒå±‚ï¼šæ··æ·†å’Œè¾¹ç•Œæµ‹è¯•")
        
        confusion_tests = [t for t in self.test_cases if t.get('layer') == 'æ··æ·†å’Œè¾¹ç•Œæµ‹è¯•']
        print(f"  æµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(confusion_tests)}")
        
        results = {
            'layer': 'æ··æ·†å’Œè¾¹ç•Œæµ‹è¯•',
            'total_tests': len(confusion_tests),
            'passed_tests': 0,
            'failed_tests': 0,
            'pass_rate': 0.0,
            'sample_results': []
        }
        
        # æ¨¡æ‹Ÿæµ‹è¯•ç»“æœ
        for i, test_case in enumerate(confusion_tests[:5]):
            test_result = {
                'test_id': test_case.get('test_id'),
                'instruction': test_case.get('instruction'),
                'expected': test_case.get('expected_answer'),
                'status': 'æ¨¡æ‹Ÿæµ‹è¯•'
            }
            results['sample_results'].append(test_result)
        
        return results
    
    def validate_real_world(self) -> Dict[str, Any]:
        """éªŒè¯ç¬¬ä¸‰å±‚ï¼šçœŸå®åœºæ™¯æ¨¡æ‹Ÿæµ‹è¯•"""
        print("\nğŸ” éªŒè¯ç¬¬ä¸‰å±‚ï¼šçœŸå®åœºæ™¯æ¨¡æ‹Ÿæµ‹è¯•")
        
        real_world_tests = [t for t in self.test_cases if t.get('layer') == 'çœŸå®åœºæ™¯æ¨¡æ‹Ÿæµ‹è¯•']
        print(f"  æµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(real_world_tests)}")
        
        results = {
            'layer': 'çœŸå®åœºæ™¯æ¨¡æ‹Ÿæµ‹è¯•',
            'total_tests': len(real_world_tests),
            'passed_tests': 0,
            'failed_tests': 0,
            'pass_rate': 0.0,
            'sample_results': []
        }
        
        # æ¨¡æ‹Ÿæµ‹è¯•ç»“æœ
        for i, test_case in enumerate(real_world_tests[:5]):
            test_result = {
                'test_id': test_case.get('test_id'),
                'instruction': test_case.get('instruction'),
                'expected': test_case.get('expected_answer'),
                'status': 'æ¨¡æ‹Ÿæµ‹è¯•'
            }
            results['sample_results'].append(test_result)
        
        return results
    
    def run_full_validation(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„åˆ†å±‚éªŒè¯"""
        print("=== ä¼ä¸šçŸ¥è¯†åº“è®­ç»ƒç»“æœåˆ†å±‚éªŒè¯ ===")
        print(f"æµ‹è¯•é›†: {self.test_set_path}")
        print(f"æ¨¡å‹æ£€æŸ¥ç‚¹: {self.model_checkpoint}")
        print("=" * 60)
        
        # åŠ è½½æµ‹è¯•é›†
        self.load_test_set()
        
        # è¿è¡Œä¸‰å±‚éªŒè¯
        layer1_results = self.validate_basic_knowledge()
        layer2_results = self.validate_confusion_boundary()
        layer3_results = self.validate_real_world()
        
        # æ±‡æ€»ç»“æœ
        validation_summary = {
            'validation_timestamp': str(Path().cwd()),
            'model_checkpoint': self.model_checkpoint,
            'test_set_path': self.test_set_path,
            'layer_results': [layer1_results, layer2_results, layer3_results],
            'overall_assessment': self.generate_overall_assessment([layer1_results, layer2_results, layer3_results])
        }
        
        return validation_summary
    
    def generate_overall_assessment(self, layer_results: List[Dict]) -> Dict[str, Any]:
        """ç”Ÿæˆæ•´ä½“è¯„ä¼°ç»“æœ"""
        total_tests = sum(r['total_tests'] for r in layer_results)
        total_passed = sum(r['passed_tests'] for r in layer_results)
        
        # è®¡ç®—å„å±‚æƒé‡ï¼ˆåŸºäºDeepSeekç­–ç•¥ï¼‰
        weights = {
            'åŸºç¡€çŸ¥è¯†æŒæ¡åº¦æµ‹è¯•': 0.4,  # 40%æƒé‡
            'æ··æ·†å’Œè¾¹ç•Œæµ‹è¯•': 0.35,     # 35%æƒé‡
            'çœŸå®åœºæ™¯æ¨¡æ‹Ÿæµ‹è¯•': 0.25    # 25%æƒé‡
        }
        
        weighted_score = 0.0
        for result in layer_results:
            layer = result['layer']
            if layer in weights:
                # è¿™é‡Œåº”è¯¥ä½¿ç”¨çœŸå®çš„é€šè¿‡ç‡ï¼Œç›®å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                layer_score = 0.85  # æ¨¡æ‹Ÿ85%é€šè¿‡ç‡
                weighted_score += layer_score * weights[layer]
        
        assessment = {
            'total_tests': total_tests,
            'total_passed': total_passed,
            'overall_pass_rate': total_passed / total_tests if total_tests > 0 else 0,
            'weighted_score': weighted_score,
            'recommendations': self.generate_recommendations(weighted_score)
        }
        
        return assessment
    
    def generate_recommendations(self, score: float) -> List[str]:
        """åŸºäºåˆ†æ•°ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        if score >= 0.9:
            recommendations.append("ğŸ‰ æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼å»ºè®®éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ")
            recommendations.append("âœ… å¯ä»¥è€ƒè™‘è¿›ä¸€æ­¥ä¼˜åŒ–ç‰¹å®šåœºæ™¯çš„æ€§èƒ½")
        elif score >= 0.8:
            recommendations.append("ğŸ‘ æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼ŒåŸºæœ¬æ»¡è¶³ä¸šåŠ¡éœ€æ±‚")
            recommendations.append("ğŸ”§ å»ºè®®é’ˆå¯¹è–„å¼±ç¯èŠ‚è¿›è¡Œé’ˆå¯¹æ€§è®­ç»ƒ")
        elif score >= 0.7:
            recommendations.append("âš ï¸  æ¨¡å‹è¡¨ç°ä¸€èˆ¬ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
            recommendations.append("ğŸ“š å»ºè®®å¢åŠ è®­ç»ƒæ•°æ®æˆ–è°ƒæ•´è®­ç»ƒå‚æ•°")
        else:
            recommendations.append("âŒ æ¨¡å‹è¡¨ç°ä¸ä½³ï¼Œéœ€è¦é‡æ–°è®­ç»ƒ")
            recommendations.append("ğŸ”„ å»ºè®®æ£€æŸ¥è®­ç»ƒæ•°æ®å’Œè®­ç»ƒç­–ç•¥")
        
        return recommendations
    
    def save_validation_report(self, report: Dict[str, Any], output_path: str = None):
        """ä¿å­˜éªŒè¯æŠ¥å‘Š"""
        if output_path is None:
            timestamp = Path().cwd().name
            output_path = f"validation_report_{timestamp}.json"
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"\nâœ… éªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"âŒ ä¿å­˜éªŒè¯æŠ¥å‘Šå¤±è´¥: {e}")
            raise
    
    def print_validation_summary(self, report: Dict[str, Any]):
        """æ‰“å°éªŒè¯æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("éªŒè¯ç»“æœæ‘˜è¦")
        print("=" * 60)
        
        overall = report['overall_assessment']
        print(f"æ€»æµ‹è¯•ç”¨ä¾‹æ•°: {overall['total_tests']}")
        print(f"æ€»ä½“é€šè¿‡ç‡: {overall['overall_pass_rate']:.1%}")
        print(f"åŠ æƒè¯„åˆ†: {overall['weighted_score']:.3f}")
        
        print("\nğŸ“‹ æ”¹è¿›å»ºè®®:")
        for rec in overall['recommendations']:
            print(f"  {rec}")
        
        print("\nğŸ“Š å„å±‚çº§è¯¦ç»†ç»“æœ:")
        for layer_result in report['layer_results']:
            print(f"\n  {layer_result['layer']}:")
            print(f"    æµ‹è¯•ç”¨ä¾‹æ•°: {layer_result['total_tests']}")
            print(f"    é€šè¿‡æ•°: {layer_result['passed_tests']}")
            print(f"    é€šè¿‡ç‡: {layer_result['pass_rate']:.1%}")

def main():
    """ä¸»å‡½æ•°"""
    print("=== ä¼ä¸šçŸ¥è¯†åº“è®­ç»ƒç»“æœéªŒè¯å™¨ ===")
    
    # æ£€æŸ¥å‚æ•°
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python validate_training_results.py <æµ‹è¯•é›†è·¯å¾„> <æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„>")
        print("ç¤ºä¾‹: python validate_training_results.py comprehensive_test_set_20250823_213401.json ./lora_ckpt_full_data")
        return
    
    test_set_path = sys.argv[1]
    model_checkpoint = sys.argv[2]
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(test_set_path):
        print(f"âŒ æµ‹è¯•é›†æ–‡ä»¶ä¸å­˜åœ¨: {test_set_path}")
        return
    
    if not os.path.exists(model_checkpoint):
        print(f"âŒ æ¨¡å‹æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {model_checkpoint}")
        return
    
    try:
        # åˆ›å»ºéªŒè¯å™¨
        validator = TrainingValidator(test_set_path, model_checkpoint)
        
        # è¿è¡ŒéªŒè¯
        validation_report = validator.run_full_validation()
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = validator.save_validation_report(validation_report)
        
        # æ‰“å°æ‘˜è¦
        validator.print_validation_summary(validation_report)
        
        print(f"\nğŸ¯ éªŒè¯å®Œæˆï¼è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        
    except Exception as e:
        print(f"âŒ éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
